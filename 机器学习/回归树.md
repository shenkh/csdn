# 回归树实现

## 回归树

- 平方误差

不同于分类树，回归树用平方误差选择切分点。若数据集按特征取值是否大于切分点值划分为两部分，则在特征$A$下，集合$D$的平方误差为：
$$
err=\sum\left(y_{1}-\overline{y_{1}}\right)^{2} )+\sum\left(y_{2}-\overline{y_{2}}\right)^{2} )
$$

面积/平米 | 价格/万
---------|--------
20 | 40.1
21 | 40.3
35 | 70.4
36 | 70.2

- 选择最优特征

**1**.按特征"面积" = 20 划分数据集，

`y1`均值为$40.1$， `y2`均值为$(40.3 + 70.4 + 70.2) / 3 = 60.3$, 则平方误差为：

$$
\begin{array}{l}{0+(40.3-60.3)^{2}+(70.4-60.3)^{2}+(70.2-60.3)^{2}} \\ {=600.02}\end{array}
$$

**2**.按特征"面积" = 21 划分数据集，则平方误差为：

`y1` 均值为$(40.1 + 40.3)/ 2 = 40.2$，`y2` 均值为$(70.4 + 70.2) / 2 = 70.3$,则平方误差为：

$$
\begin{array}{l}{(40.1-40.2)^{2}+(40.3-40.2)^{2}+(70.4-70.3)^{2}+(70.2-70.3)^{2}} \\ {=0.04}\end{array}
$$

**3**.按特征"面积" = 35 划分数据集，则平方误差为：

`y1`均值为(40.1 + 40.3 + 70.4) / 3 = 50.27，`y2`均值为 70.2,则平方误差为：

$$
\begin{array}{l}{(40.1-50.27)^{2}+(40.3-50.27)^{2}+(70.4-50.27)^{2}+0} \\ {=608.05}\end{array}
$$

综上所述，由于按特征"面积" = 21 比特征"面积" = 20、"面积" = 35 划分的平方误差小，所以特征"面积" = 21 为切分点。

## 代码实现

```python
# -*-coding:utf-8-*-
import pandas as pd
import numpy as np


class RegressionTree:

    def __init__(self, features, y):
        self.features = features
        self.y = y

    def __calcError(self, y):
        return y.var() * y.size

    def __chooseBestFeatVal(self, features, y):
        if(y.unique().size == 1):
            return None, None
        best_feature_name = None
        split_value = 0
        lowest_error = 10e5

        # http://kekefund.com/2016/02/23/pandas-anlysis-basic/
        # 1，按行遍历 for ix, row in df.iterrows():
        # 2，按列遍历 for ix, col in df.iteritems():

        for name, feature in features.iteritems():
            values = feature.unique()
            for value in values:
                left_child = y[feature > value]
                right_child = y[feature <= value]
                cur_error = self.__calcError(
                    left_child) + self.__calcError(right_child)

                if cur_error < lowest_error:
                    best_feature_name = name
                    split_value = value
                    lowest_error = cur_error

        total_error = self.__calcError(y)
        if total_error - lowest_error < 1:
            return None, None
        return best_feature_name, split_value

    def buildTree(self, features, y):
        best_feature_name, split_value = self.__chooseBestFeatVal(features, y)
        # 如果无法继续分割，则返回对应的均值
        if best_feature_name == None:
            return y.mean()
        tree_dict = {}
        tree_dict['feature'] = best_feature_name
        tree_dict['split_value'] = split_value

        # 左子树的值比夫结点的值大， 右子树的值比父结点的值小
        features_right = features[features[best_feature_name] <= split_value]
        y_right = y[features[best_feature_name] <= split_value]
        tree_dict['right'] = self.buildTree(features_right, y_right)

        features_left = features[features[best_feature_name] > split_value]
        y_left = y[features[best_feature_name] > split_value]
        tree_dict['left'] = self.buildTree(features_left, y_left)

        return tree_dict


if __name__ == "__main__":
    df = pd.read_csv('regression.csv', encoding='gb2312')
    regression_tree = RegressionTree(df[df.columns[0:2]], df[df.columns[-1]])
    info = regression_tree.buildTree(
        df[df.columns[0:2]], df[df.columns[-1]])
    print(info)

```

评价 | 平方数 |价格
-----|-------|----
5.23 | 1     | 0.1
5.23 | 2     | 0.12
5.23 | 3     | 0.02
5.23 | 4     | 0.03
5.23 | 5     | 0.12
5.23 | 6     | 5
5.23 | 7     | 5.2
5.23 | 8     | 5.1
5.23 | 9     | 5.02
5.23 | 10    | 5.03
5.23 | 11    | 10.8
5.23 | 12    | 10.06
5.23 | 13    | 10.03
5.23 | 14    | 10.02
5.23 | 15    | 10.44
5.23 | 16    | 15.88
5.23 | 17    | 15.06
5.23 | 18    | 15.04
5.23 | 19    | 15.3

数据来源：[机器学习系列之手把手教你实现一个分类回归树](https://www.ibm.com/developerworks/cn/analytics/library/machine-learning-hands-on5-cart-tree/index.html)

{'feature': '平方数', 'split_value': 10, 'right': {'feature': '平方数', 'split_value': 5, 'right': 0.078, 'left': 5.07}, 'left': {'feature': '平方数', 'split_value': 15, 'right': 10.27, 'left': 15.32}}

**参考**：

[机器学习系列之手把手教你实现一个分类回归树](https://www.ibm.com/developerworks/cn/analytics/library/machine-learning-hands-on5-cart-tree/index.html)