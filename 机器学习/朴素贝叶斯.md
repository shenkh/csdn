# 朴素贝叶斯

## 原理介绍

![Naive Bayes Classifier Photo by [Matt Buck](https://www.flickr.com/photos/mattbuck007/3676624894), some rights reserved](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2014/12/naive-bayes-classifier.jpg)

*Naive Bayes Classifier Photo by [Matt Buck](https://www.flickr.com/photos/mattbuck007/3676624894), some rights reserved*

训练数据集
$$
T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}
$$
朴素贝叶斯通过训练数据学习联合概率分布$P(X,Y)$，具体地，学习先验概率和条件概率。

先验概率：
$$
P\left(Y=c_{k}\right), \quad k=1,2, \cdots, K
$$
条件概率分布：
$$
P\left(X=x | Y=c_{k}\right)=P\left(X^{(1)}=x^{(1)}, \cdots, X^{(n)}=x^{(n)} | Y=c_{k}\right), \quad k=1,2, \cdots, K
$$
条件概率分布有指数级的参数，朴素贝叶斯对条件概率分布作了**条件独立性假设**，具体地：
$$
\begin{aligned} P\left(X=x | Y=c_{k}\right) &=P\left(X^{(1)}=x^{(1)}, \cdots, X^{(n)}=x^{(n)} | Y=c_{k}\right) \\ &=\prod_{j=1}^{n} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right) \end{aligned}
$$
后验概率根据贝叶斯定理计算
$$
P\left(Y=c_{k} | X=x\right)=\frac{P\left(X=x | Y=c_{k}\right) P\left(Y=c_{k}\right)}{\sum_{k} P\left(X=x | Y=c_{k}\right) P\left(Y=c_{k}\right)}
$$
即
$$
P\left(Y=c_{k} | X=x\right)=\frac{P\left(Y=c_{k}\right) \prod_{j} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}{\sum_{k} P\left(Y=c_{k}\right) \prod_{j} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}, \quad k=1,2, \cdots, K
$$
贝叶斯分类器为：
$$
y=f(x)=\arg \max _{c_{k}} \frac{P\left(Y=c_{k}\right) \prod_{j} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}{\sum_{k} P\left(Y=c_{k}\right) \prod_{j} P\left(X^{(j)}=x^{(j)} | Y=c_{k}\right)}
$$
对于特征属性是连续值地情况，类条件概率计算时，假定变量服从某种概率分布，用训练数据估计分布地参数，常用高斯分布（均值，方差）。

## 代码实现

```python
# -*-coding:utf-8-*-
import pandas as pd
import numpy as np


class NaiveBayes():

    def __init__(self, x, y):
        self.x = x
        self.y = y

    def splitDataset(self, trainset_ratio=0.7):
        r = int(self.x.shape[0]*trainset_ratio)
        train_x,  train_y = self.x.iloc[0:r], self.y.iloc[0:r]
        test_x,  test_y = self.x.iloc[r:], self.y.iloc[r:]
        return train_x, train_y, test_x, test_y

    def fit(self, train_x, train_y):
        y_values = train_y.unique()
        self.class_nums = y_values.size

        self.priori_prob = {}
        self.conditional_prob = {}
        for y_val in y_values:
            # 先验概率
            self.priori_prob[y_val] = len(
                train_y[train_y == y_val]) / len(train_y)
            # 类条件概率
            train_x_class_y = train_x[train_y == y_val]
            mean, var = train_x_class_y.mean(
                axis=0), train_x_class_y.var(axis=0)
            self.conditional_prob[y_val] = mean, var

    def predict(self, x):
        eps = 1e-4
        posterior_prob = np.zeros((x.shape[0], self.class_nums))
        for y_class, value in self.conditional_prob.items():
            mu, var = value[0], value[1]
            class_condition_prob = 1 / (np.sqrt(2*np.pi*var)) * \
                np.exp(-(x-mu)**2/(2*var + eps))
            posterior_prob[:, y_class] = self.priori_prob[y_class] * \
                np.prod(class_condition_prob.to_numpy(), axis=1)
        predict = np.argmax(posterior_prob, axis=1)
        return predict


if __name__ == "__main__":
    df = pd.read_csv('pima-indians-diabetes.data.csv', header=None)
    naive_bayes = NaiveBayes(df[df.columns[0:-1]], df[df.columns[-1]])
    train_x, train_y, test_x, test_y = naive_bayes.splitDataset()
    naive_bayes.fit(train_x, train_y)
    predict_y = naive_bayes.predict(test_x)

    print(np.sum(predict_y == test_y) / test_y.size)
    print(test_y, predict_y)

```

使用的数据集，[下载地址](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv)
|feat1|feat2|feat3|feat4|feat5|feat6|feat7|feat8|label|
|---- | ---- | ---- | ---- | ---- | ---- | ----- | ---- | -----|
|1|85|66|29|0|26.6|0.351|31|0|
|8|183|64|0|0|23.3|0.672|32|1|
|1|89|66|23|94|28.1|0.167|21|0|
|0|137|40|35|168|43.1|2.288|33|1|
|5|116|74|0|0|25.6|0.201|30|0|
|3|78|50|32|88|31.0|0.248|26|1|

**参考**

统计学习方法 李航

[How To Implement Naive Bayes From Scratch in Python](<https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/>)

[Python从0实现朴素贝叶斯分类器](<https://www.jianshu.com/p/d2745c85bbd4>)



