<https://zhuanlan.zhihu.com/p/24709748>



矩阵求导的技术，在统计学、控制论、机器学习等领域有广泛的应用。鉴于我看过的一些资料或言之不详、或繁乱无绪，本文来做个科普，分作两篇，上篇讲标量对矩阵的求导术，下篇讲矩阵对矩阵的求导术。本文使用小写字母x表示标量，粗体小写字母![\boldsymbol{x} ](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bx%7D+)表示（列）向量，大写字母X表示矩阵。



首先来琢磨一下定义，标量f对矩阵X的导数，定义为![\frac{\partial f}{\partial X} = \left[\frac{\partial f }{\partial X_{ij}}\right]](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D+%3D+%5Cleft%5B%5Cfrac%7B%5Cpartial+f+%7D%7B%5Cpartial+X_%7Bij%7D%7D%5Cright%5D)，即f对X逐元素求导排成与X尺寸相同的矩阵。然而，这个定义在计算中并不好用，实用上的原因是对函数较复杂的情形难以逐元素求导；哲理上的原因是逐元素求导破坏了**整体性**。试想，为何要将f看做矩阵X而不是各元素![X_{ij}](https://www.zhihu.com/equation?tex=X_%7Bij%7D)的函数呢？答案是用矩阵运算更整洁。所以在求导时不宜拆开矩阵，而是要找一个从整体出发的算法。



为此，我们来回顾，一元微积分中的导数（标量对标量的导数）与微分有联系：![df = f'(x)dx](https://www.zhihu.com/equation?tex=df+%3D+f%27%28x%29dx)；多元微积分中的梯度（标量对向量的导数）也与微分有联系：![df = \sum_{i=1}^n \frac{\partial f}{\partial x_i}dx_i = \frac{\partial f}{\partial \boldsymbol{x}}^T d\boldsymbol{x} ](https://www.zhihu.com/equation?tex=df+%3D+%5Csum_%7Bi%3D1%7D%5En+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x_i%7Ddx_i+%3D+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+%5Cboldsymbol%7Bx%7D%7D%5ET+d%5Cboldsymbol%7Bx%7D+)，这里第一个等号是全微分公式，第二个等号表达了梯度与微分的联系：全微分![df](https://www.zhihu.com/equation?tex=df)是梯度向量![\frac{\partial f}{\partial \boldsymbol{x}}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+%5Cboldsymbol%7Bx%7D%7D)(n×1)与微分向量![d\boldsymbol{x}](https://www.zhihu.com/equation?tex=d%5Cboldsymbol%7Bx%7D)(n×1)的内积；受此启发，我们将矩阵导数与微分建立联系：![df = \sum_{i=1}^m \sum_{j=1}^n \frac{\partial f}{\partial X_{ij}}dX_{ij} = \text{tr}\left(\frac{\partial f}{\partial X}^T dX\right) ](https://www.zhihu.com/equation?tex=df+%3D+%5Csum_%7Bi%3D1%7D%5Em+%5Csum_%7Bj%3D1%7D%5En+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X_%7Bij%7D%7DdX_%7Bij%7D+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D%5ET+dX%5Cright%29+)。其中tr代表迹(trace)是方阵对角线元素之和，满足性质：对尺寸相同的矩阵A,B，![\text{tr}(A^TB) = \sum_{i,j}A_{ij}B_{ij}](https://www.zhihu.com/equation?tex=%5Ctext%7Btr%7D%28A%5ETB%29+%3D+%5Csum_%7Bi%2Cj%7DA_%7Bij%7DB_%7Bij%7D)，即![\text{tr}(A^TB)](https://www.zhihu.com/equation?tex=%5Ctext%7Btr%7D%28A%5ETB%29)是矩阵A,B的**内积**。与梯度相似，这里第一个等号是全微分公式，第二个等号表达了矩阵导数与微分的联系：全微分![df](https://www.zhihu.com/equation?tex=df)是导数![\frac{\partial f}{\partial X}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D)(m×n)与微分矩阵![dX](https://www.zhihu.com/equation?tex=dX)(m×n)的内积。



然后来建立运算法则。回想遇到较复杂的一元函数如![f = \log(2+\sin x)e^{\sqrt{x}}](https://www.zhihu.com/equation?tex=f+%3D+%5Clog%282%2B%5Csin+x%29e%5E%7B%5Csqrt%7Bx%7D%7D)，我们是如何求导的呢？通常不是从定义开始求极限，而是先建立了初等函数求导和四则运算、复合等法则，再来运用这些法则。故而，我们来创立常用的矩阵微分的运算法则：

1. 加减法：![d(X\pm Y) = dX \pm dY](https://www.zhihu.com/equation?tex=d%28X%5Cpm+Y%29+%3D+dX+%5Cpm+dY)；矩阵乘法：![d(XY) = (dX)Y + X dY ](https://www.zhihu.com/equation?tex=d%28XY%29+%3D+%28dX%29Y+%2B+X+dY+)；转置：![d(X^T) = (dX)^T](https://www.zhihu.com/equation?tex=d%28X%5ET%29+%3D+%28dX%29%5ET)；迹：![d\text{tr}(X) = \text{tr}(dX)](https://www.zhihu.com/equation?tex=d%5Ctext%7Btr%7D%28X%29+%3D+%5Ctext%7Btr%7D%28dX%29)。
2. 逆：![dX^{-1} = -X^{-1}dX X^{-1}](https://www.zhihu.com/equation?tex=dX%5E%7B-1%7D+%3D+-X%5E%7B-1%7DdX+X%5E%7B-1%7D)。此式可在![XX^{-1}=I](https://www.zhihu.com/equation?tex=XX%5E%7B-1%7D%3DI)两侧求微分来证明。
3. 行列式：![d|X| = \text{tr}(X^{\#}dX) ](https://www.zhihu.com/equation?tex=d%7CX%7C+%3D+%5Ctext%7Btr%7D%28X%5E%7B%5C%23%7DdX%29+)，其中![X^{\#}](https://www.zhihu.com/equation?tex=X%5E%7B%5C%23%7D)表示X的伴随矩阵，在X可逆时又可以写作![d|X|= |X|\text{tr}(X^{-1}dX)](https://www.zhihu.com/equation?tex=d%7CX%7C%3D+%7CX%7C%5Ctext%7Btr%7D%28X%5E%7B-1%7DdX%29)。此式可用Laplace展开来证明，详见张贤达《矩阵分析与应用》第279页。
4. 逐元素乘法：![d(X\odot Y) = dX\odot Y + X\odot dY](https://www.zhihu.com/equation?tex=d%28X%5Codot+Y%29+%3D+dX%5Codot+Y+%2B+X%5Codot+dY)，![\odot](https://www.zhihu.com/equation?tex=%5Codot)表示尺寸相同的矩阵X,Y逐元素相乘。
5. 逐元素函数：![d\sigma(X) = \sigma'(X)\odot dX ](https://www.zhihu.com/equation?tex=d%5Csigma%28X%29+%3D+%5Csigma%27%28X%29%5Codot+dX+)，![\sigma(X) = \left[\sigma(X_{ij})\right]](https://www.zhihu.com/equation?tex=%5Csigma%28X%29+%3D+%5Cleft%5B%5Csigma%28X_%7Bij%7D%29%5Cright%5D)是逐元素标量函数运算， ![\sigma'(X)=[\sigma'(X_{ij})]](https://www.zhihu.com/equation?tex=%5Csigma%27%28X%29%3D%5B%5Csigma%27%28X_%7Bij%7D%29%5D)是逐元素求导数。举个例子，![X=\left[\begin{matrix}x_{11} & x_{12} \\ x_{21} & x_{22}\end{matrix}\right], d \sin(X) = \left[\begin{matrix}\cos x_{11} dx_{11} & \cos x_{12} d x_{12}\\ \cos x_{21} d x_{21}& \cos x_{22} dx_{22}\end{matrix}\right] = \cos(X)\odot dX](https://www.zhihu.com/equation?tex=X%3D%5Cleft%5B%5Cbegin%7Bmatrix%7Dx_%7B11%7D+%26+x_%7B12%7D+%5C%5C+x_%7B21%7D+%26+x_%7B22%7D%5Cend%7Bmatrix%7D%5Cright%5D%2C+d+%5Csin%28X%29+%3D+%5Cleft%5B%5Cbegin%7Bmatrix%7D%5Ccos+x_%7B11%7D+dx_%7B11%7D+%26+%5Ccos+x_%7B12%7D+d+x_%7B12%7D%5C%5C+%5Ccos+x_%7B21%7D+d+x_%7B21%7D%26+%5Ccos+x_%7B22%7D+dx_%7B22%7D%5Cend%7Bmatrix%7D%5Cright%5D+%3D+%5Ccos%28X%29%5Codot+dX)。



我们试图利用矩阵导数与微分的联系![df = \text{tr}\left(\frac{\partial f}{\partial X}^T dX\right) ](https://www.zhihu.com/equation?tex=df+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D%5ET+dX%5Cright%29+)，在求出左侧的微分![df](https://www.zhihu.com/equation?tex=df)后，该如何写成右侧的形式并得到导数呢？这需要一些迹技巧(trace trick)：

1. 标量套上迹：![a = \text{tr}(a)](https://www.zhihu.com/equation?tex=a+%3D+%5Ctext%7Btr%7D%28a%29)
2. 转置：![\mathrm{tr}(A^T) = \mathrm{tr}(A)](https://www.zhihu.com/equation?tex=%5Cmathrm%7Btr%7D%28A%5ET%29+%3D+%5Cmathrm%7Btr%7D%28A%29)。
3. 线性：![\text{tr}(A\pm B) = \text{tr}(A)\pm \text{tr}(B)](https://www.zhihu.com/equation?tex=%5Ctext%7Btr%7D%28A%5Cpm+B%29+%3D+%5Ctext%7Btr%7D%28A%29%5Cpm+%5Ctext%7Btr%7D%28B%29)。
4. 矩阵乘法交换：![\text{tr}(AB) = \text{tr}(BA)](https://www.zhihu.com/equation?tex=%5Ctext%7Btr%7D%28AB%29+%3D+%5Ctext%7Btr%7D%28BA%29)，其中![A](https://www.zhihu.com/equation?tex=A)与![B^T](https://www.zhihu.com/equation?tex=B%5ET)尺寸相同。两侧都等于![\sum_{i,j}A_{ij}B_{ji}](https://www.zhihu.com/equation?tex=%5Csum_%7Bi%2Cj%7DA_%7Bij%7DB_%7Bji%7D)。
5. 矩阵乘法/逐元素乘法交换：![\text{tr}(A^T(B\odot C)) = \text{tr}((A\odot B)^TC)](https://www.zhihu.com/equation?tex=%5Ctext%7Btr%7D%28A%5ET%28B%5Codot+C%29%29+%3D+%5Ctext%7Btr%7D%28%28A%5Codot+B%29%5ETC%29)，其中![A, B, C](https://www.zhihu.com/equation?tex=A%2C+B%2C+C)尺寸相同。两侧都等于![\sum_{i,j}A_{ij}B_{ij}C_{ij}](https://www.zhihu.com/equation?tex=%5Csum_%7Bi%2Cj%7DA_%7Bij%7DB_%7Bij%7DC_%7Bij%7D)。



观察一下可以断言，**若标量函数f是矩阵X经加减乘法、逆、行列式、逐元素函数等运算构成，则使用相应的运算法则对f求微分，再使用迹技巧给df套上迹并将其它项交换至dX左侧，对照导数与微分的联系![df = \text{tr}\left(\frac{\partial f}{\partial X}^T dX\right) ](https://www.zhihu.com/equation?tex=df+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D%5ET+dX%5Cright%29+)，即能得到导数。**

**特别地，若矩阵退化为向量，对照导数与微分的联系**![df = \frac{\partial f}{\partial \boldsymbol{x}}^T d\boldsymbol{x} ](https://www.zhihu.com/equation?tex=df+%3D+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+%5Cboldsymbol%7Bx%7D%7D%5ET+d%5Cboldsymbol%7Bx%7D+)**，即能得到导数。**



在建立法则的最后，来谈一谈复合：假设已求得![\frac{\partial f}{\partial Y}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+Y%7D)，而Y是X的函数，如何求![\frac{\partial f}{\partial X}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D)呢？在微积分中有标量求导的链式法则![\frac{\partial f}{\partial x} = \frac{\partial f}{\partial y} \frac{\partial y}{\partial x}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x%7D+%3D+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+y%7D+%5Cfrac%7B%5Cpartial+y%7D%7B%5Cpartial+x%7D)，但这里我们**不能随意沿用标量的链式法则**，因为矩阵对矩阵的导数![\frac{\partial Y}{\partial X}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+Y%7D%7B%5Cpartial+X%7D)截至目前仍是未定义的。于是我们继续追本溯源，链式法则是从何而来？源头仍然是微分。我们直接从微分入手建立复合法则：先写出![df = \text{tr}\left(\frac{\partial f}{\partial Y}^T dY\right)](https://www.zhihu.com/equation?tex=df+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+Y%7D%5ET+dY%5Cright%29)，再将dY用dX表示出来代入，并使用迹技巧将其他项交换至dX左侧，即可得到![\frac{\partial f}{\partial X}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D)。

最常见的情形是![Y = AXB](https://www.zhihu.com/equation?tex=Y+%3D+AXB)，此时 ![df = \text{tr}\left(\frac{\partial f}{\partial Y}^T dY\right) = \text{tr}\left(\frac{\partial f}{\partial Y}^T AdXB\right) =  \text{tr}\left(B\frac{\partial f}{\partial Y}^T AdX\right) = \text{tr}\left((A^T\frac{\partial f}{\partial Y}B^T)^T dX\right)](https://www.zhihu.com/equation?tex=df+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+Y%7D%5ET+dY%5Cright%29+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+Y%7D%5ET+AdXB%5Cright%29+%3D++%5Ctext%7Btr%7D%5Cleft%28B%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+Y%7D%5ET+AdX%5Cright%29+%3D+%5Ctext%7Btr%7D%5Cleft%28%28A%5ET%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+Y%7DB%5ET%29%5ET+dX%5Cright%29)，可得到![\frac{\partial f}{\partial X}=A^T\frac{\partial f}{\partial Y}B^T](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D%3DA%5ET%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+Y%7DB%5ET)。注意这里![dY = (dA)XB + AdXB + AXdB = AdXB](https://www.zhihu.com/equation?tex=dY+%3D+%28dA%29XB+%2B+AdXB+%2B+AXdB+%3D+AdXB)，由于![A,B](https://www.zhihu.com/equation?tex=A%2CB)是常量，![dA=0,dB=0](https://www.zhihu.com/equation?tex=dA%3D0%2CdB%3D0)，以及我们使用矩阵乘法交换的迹技巧交换了![\frac{\partial f}{\partial Y}^T AdX](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+Y%7D%5ET+AdX)与![B](https://www.zhihu.com/equation?tex=B)。



接下来演示一些算例。特别提醒要依据已经建立的运算法则来计算，不能随意套用微积分中标量导数的结论，比如认为AX对X的导数为A，这是没有根据、意义不明的。

例1：![f = \boldsymbol{a}^T X\boldsymbol{b}](https://www.zhihu.com/equation?tex=f+%3D+%5Cboldsymbol%7Ba%7D%5ET+X%5Cboldsymbol%7Bb%7D)，求![\frac{\partial f}{\partial X}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D)。其中![\boldsymbol{a}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Ba%7D)是![m×1](https://www.zhihu.com/equation?tex=m%C3%971)列向量，![X](https://www.zhihu.com/equation?tex=X)是![m\times n](https://www.zhihu.com/equation?tex=m%5Ctimes+n)矩阵，![\boldsymbol{b}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bb%7D)是![n×1](https://www.zhihu.com/equation?tex=n%C3%971)列向量，![f](https://www.zhihu.com/equation?tex=f)是标量。

解：先使用矩阵乘法法则求微分，![df = d\boldsymbol{a}^TX\boldsymbol{b}+\boldsymbol{a}^TdX\boldsymbol{b}+\boldsymbol{a}^TXd\boldsymbol{b} = \boldsymbol{a}^TdX\boldsymbol{b}](https://www.zhihu.com/equation?tex=df+%3D+d%5Cboldsymbol%7Ba%7D%5ETX%5Cboldsymbol%7Bb%7D%2B%5Cboldsymbol%7Ba%7D%5ETdX%5Cboldsymbol%7Bb%7D%2B%5Cboldsymbol%7Ba%7D%5ETXd%5Cboldsymbol%7Bb%7D+%3D+%5Cboldsymbol%7Ba%7D%5ETdX%5Cboldsymbol%7Bb%7D)，注意这里的![\boldsymbol{a}, \boldsymbol{b}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Ba%7D%2C+%5Cboldsymbol%7Bb%7D)是常量，![d\boldsymbol{a} = \boldsymbol{0}, d\boldsymbol{b} = \boldsymbol{0}](https://www.zhihu.com/equation?tex=d%5Cboldsymbol%7Ba%7D+%3D+%5Cboldsymbol%7B0%7D%2C+d%5Cboldsymbol%7Bb%7D+%3D+%5Cboldsymbol%7B0%7D)。由于df是标量，它的迹等于自身，![df = \text{tr}(df)](https://www.zhihu.com/equation?tex=df+%3D+%5Ctext%7Btr%7D%28df%29)，套上迹并做矩阵乘法交换：![df = \text{tr}(\boldsymbol{a}^TdX\boldsymbol{b}) = \text{tr}(\boldsymbol{b}\boldsymbol{a}^TdX)= \text{tr}((\boldsymbol{a}\boldsymbol{b}^T)^TdX)](https://www.zhihu.com/equation?tex=df+%3D+%5Ctext%7Btr%7D%28%5Cboldsymbol%7Ba%7D%5ETdX%5Cboldsymbol%7Bb%7D%29+%3D+%5Ctext%7Btr%7D%28%5Cboldsymbol%7Bb%7D%5Cboldsymbol%7Ba%7D%5ETdX%29%3D+%5Ctext%7Btr%7D%28%28%5Cboldsymbol%7Ba%7D%5Cboldsymbol%7Bb%7D%5ET%29%5ETdX%29)，注意这里我们根据![\text{tr}(AB) = \text{tr}(BA)](https://www.zhihu.com/equation?tex=%5Ctext%7Btr%7D%28AB%29+%3D+%5Ctext%7Btr%7D%28BA%29)交换了![\boldsymbol{a}^TdX](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Ba%7D%5ETdX)与![\boldsymbol{b}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bb%7D)。对照导数与微分的联系![df = \text{tr}\left(\frac{\partial f}{\partial X}^T dX\right)](https://www.zhihu.com/equation?tex=df+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D%5ET+dX%5Cright%29)，得到![\frac{\partial f}{\partial X} = \boldsymbol{a}\boldsymbol{b}^T](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D+%3D+%5Cboldsymbol%7Ba%7D%5Cboldsymbol%7Bb%7D%5ET)。

注意：这里不能用![\frac{\partial f}{\partial X} =\boldsymbol{a}^T \frac{\partial X}{\partial X}\boldsymbol{b}=?](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D+%3D%5Cboldsymbol%7Ba%7D%5ET+%5Cfrac%7B%5Cpartial+X%7D%7B%5Cpartial+X%7D%5Cboldsymbol%7Bb%7D%3D%3F)，导数与矩阵乘法的交换是不合法则的运算（而微分是合法的）。有些资料在计算矩阵导数时，会略过求微分这一步，这是逻辑上解释不通的。



例2：![f = \boldsymbol{a}^T \exp(X\boldsymbol{b})](https://www.zhihu.com/equation?tex=f+%3D+%5Cboldsymbol%7Ba%7D%5ET+%5Cexp%28X%5Cboldsymbol%7Bb%7D%29)，求![\frac{\partial f}{\partial X}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D)。其中![\boldsymbol{a}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Ba%7D)是![m×1](https://www.zhihu.com/equation?tex=m%C3%971)列向量，![X](https://www.zhihu.com/equation?tex=X)是![m\times n](https://www.zhihu.com/equation?tex=m%5Ctimes+n)矩阵，![\boldsymbol{b}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bb%7D)是![n×1](https://www.zhihu.com/equation?tex=n%C3%971)列向量，exp表示逐元素求指数，![f](https://www.zhihu.com/equation?tex=f)是标量。

解：先使用矩阵乘法、逐元素函数法则求微分：![df = \boldsymbol{a}^T(\exp(X\boldsymbol{b})\odot (dX\boldsymbol{b}))](https://www.zhihu.com/equation?tex=df+%3D+%5Cboldsymbol%7Ba%7D%5ET%28%5Cexp%28X%5Cboldsymbol%7Bb%7D%29%5Codot+%28dX%5Cboldsymbol%7Bb%7D%29%29)，再套上迹并做交换：![df = \text{tr}( \boldsymbol{a}^T(\exp(X\boldsymbol{b})\odot (dX\boldsymbol{b}))) =\text{tr}((\boldsymbol{a}\odot \exp(X\boldsymbol{b}))^TdX \boldsymbol{b}) ](https://www.zhihu.com/equation?tex=df+%3D+%5Ctext%7Btr%7D%28+%5Cboldsymbol%7Ba%7D%5ET%28%5Cexp%28X%5Cboldsymbol%7Bb%7D%29%5Codot+%28dX%5Cboldsymbol%7Bb%7D%29%29%29+%3D%5Ctext%7Btr%7D%28%28%5Cboldsymbol%7Ba%7D%5Codot+%5Cexp%28X%5Cboldsymbol%7Bb%7D%29%29%5ETdX+%5Cboldsymbol%7Bb%7D%29+)![= \text{tr}(\boldsymbol{b}(\boldsymbol{a}\odot \exp(X\boldsymbol{b}))^TdX) = \text{tr}(((\boldsymbol{a}\odot \exp(X\boldsymbol{b}))\boldsymbol{b}^T)^TdX)](https://www.zhihu.com/equation?tex=%3D+%5Ctext%7Btr%7D%28%5Cboldsymbol%7Bb%7D%28%5Cboldsymbol%7Ba%7D%5Codot+%5Cexp%28X%5Cboldsymbol%7Bb%7D%29%29%5ETdX%29+%3D+%5Ctext%7Btr%7D%28%28%28%5Cboldsymbol%7Ba%7D%5Codot+%5Cexp%28X%5Cboldsymbol%7Bb%7D%29%29%5Cboldsymbol%7Bb%7D%5ET%29%5ETdX%29)，注意这里我们先根据![\text{tr}(A^T(B\odot C)) = \text{tr}((A\odot B)^TC)](https://www.zhihu.com/equation?tex=%5Ctext%7Btr%7D%28A%5ET%28B%5Codot+C%29%29+%3D+%5Ctext%7Btr%7D%28%28A%5Codot+B%29%5ETC%29)交换了![\boldsymbol{a}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Ba%7D)、![\exp(X\boldsymbol{b})](https://www.zhihu.com/equation?tex=%5Cexp%28X%5Cboldsymbol%7Bb%7D%29)与![dX\boldsymbol{b}](https://www.zhihu.com/equation?tex=dX%5Cboldsymbol%7Bb%7D)，再根据![\text{tr}(AB) = \text{tr}(BA)](https://www.zhihu.com/equation?tex=%5Ctext%7Btr%7D%28AB%29+%3D+%5Ctext%7Btr%7D%28BA%29)交换了![(\boldsymbol{a}\odot \exp(X\boldsymbol{b}))^TdX](https://www.zhihu.com/equation?tex=%28%5Cboldsymbol%7Ba%7D%5Codot+%5Cexp%28X%5Cboldsymbol%7Bb%7D%29%29%5ETdX)与![\boldsymbol{b}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bb%7D)。对照导数与微分的联系![df = \text{tr}\left(\frac{\partial f}{\partial X}^T dX\right)](https://www.zhihu.com/equation?tex=df+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D%5ET+dX%5Cright%29)，得到![\frac{\partial f}{\partial X} = (\boldsymbol{a}\odot \exp(X\boldsymbol{b}))\boldsymbol{b}^T](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D+%3D+%28%5Cboldsymbol%7Ba%7D%5Codot+%5Cexp%28X%5Cboldsymbol%7Bb%7D%29%29%5Cboldsymbol%7Bb%7D%5ET)。



例3：![f = \text{tr}(Y^T M Y), Y = \sigma(WX)](https://www.zhihu.com/equation?tex=f+%3D+%5Ctext%7Btr%7D%28Y%5ET+M+Y%29%2C+Y+%3D+%5Csigma%28WX%29)，求![\frac{\partial f}{\partial X}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D)。其中![W](https://www.zhihu.com/equation?tex=W)是![l×m](https://www.zhihu.com/equation?tex=l%C3%97m)列向量，![X](https://www.zhihu.com/equation?tex=X)是![m\times n](https://www.zhihu.com/equation?tex=m%5Ctimes+n)矩阵，![Y](https://www.zhihu.com/equation?tex=Y)是![l\times n](https://www.zhihu.com/equation?tex=l%5Ctimes+n)矩阵，![M](https://www.zhihu.com/equation?tex=M)是![l×l](https://www.zhihu.com/equation?tex=l%C3%97l)对称矩阵，![\sigma](https://www.zhihu.com/equation?tex=%5Csigma)是逐元素函数，![f](https://www.zhihu.com/equation?tex=f)是标量。

解：先求![\frac{\partial f}{\partial Y}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+Y%7D)，求微分，使用矩阵乘法、转置法则：![df = \text{tr}((dY)^TMY) + \text{tr}(Y^TMdY) = \text{tr}(Y^TM^TdY) + \text{tr}(Y^TMdY) = \text{tr}(Y^T(M+M^T)dY)](https://www.zhihu.com/equation?tex=df+%3D+%5Ctext%7Btr%7D%28%28dY%29%5ETMY%29+%2B+%5Ctext%7Btr%7D%28Y%5ETMdY%29+%3D+%5Ctext%7Btr%7D%28Y%5ETM%5ETdY%29+%2B+%5Ctext%7Btr%7D%28Y%5ETMdY%29+%3D+%5Ctext%7Btr%7D%28Y%5ET%28M%2BM%5ET%29dY%29)，对照导数与微分的联系，得到![\frac{\partial f}{\partial Y}=(M+M^T)Y = 2MY](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+Y%7D%3D%28M%2BM%5ET%29Y+%3D+2MY)，注意这里M是对称矩阵。为求![\frac{\partial f}{\partial X}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D)，写出![df = \text{tr}\left(\frac{\partial f}{\partial Y}^T dY\right)](https://www.zhihu.com/equation?tex=df+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+Y%7D%5ET+dY%5Cright%29)，再将dY用dX表示出来代入，并使用矩阵乘法/逐元素乘法交换：![df = \text{tr}\left(\frac{\partial f}{\partial Y}^T (\sigma'(WX)\odot (WdX))\right) = \text{tr}\left(\left(\frac{\partial f}{\partial Y} \odot \sigma'(WX)\right)^T W dX\right)](https://www.zhihu.com/equation?tex=df+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+Y%7D%5ET+%28%5Csigma%27%28WX%29%5Codot+%28WdX%29%29%5Cright%29+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cleft%28%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+Y%7D+%5Codot+%5Csigma%27%28WX%29%5Cright%29%5ET+W+dX%5Cright%29)，对照导数与微分的联系，得到![\frac{\partial f}{\partial X}=W^T \left(\frac{\partial f}{\partial Y}\odot \sigma'(WX)\right)=W^T((2M\sigma(WX))\odot\sigma'(WX))](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+X%7D%3DW%5ET+%5Cleft%28%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+Y%7D%5Codot+%5Csigma%27%28WX%29%5Cright%29%3DW%5ET%28%282M%5Csigma%28WX%29%29%5Codot%5Csigma%27%28WX%29%29)。



例4【线性回归】：![l = \|X\boldsymbol{w}- \boldsymbol{y}\|^2](https://www.zhihu.com/equation?tex=l+%3D+%5C%7CX%5Cboldsymbol%7Bw%7D-+%5Cboldsymbol%7By%7D%5C%7C%5E2)， 求![\boldsymbol{w}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bw%7D)的最小二乘估计，即求![\frac{\partial l}{\partial \boldsymbol{w}}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Bw%7D%7D)的零点。其中![\boldsymbol{y}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7By%7D)是![m×1](https://www.zhihu.com/equation?tex=m%C3%971)列向量，![X](https://www.zhihu.com/equation?tex=X)是![m\times n](https://www.zhihu.com/equation?tex=m%5Ctimes+n)矩阵，![\boldsymbol{w}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bw%7D)是![n×1](https://www.zhihu.com/equation?tex=n%C3%971)列向量，![l](https://www.zhihu.com/equation?tex=l)是标量。

解：这是标量对向量的导数，不过可以把向量看做矩阵的特例。先将向量模平方改写成向量与自身的内积：![l = (X\boldsymbol{w}- \boldsymbol{y})^T(X\boldsymbol{w}- \boldsymbol{y})](https://www.zhihu.com/equation?tex=l+%3D+%28X%5Cboldsymbol%7Bw%7D-+%5Cboldsymbol%7By%7D%29%5ET%28X%5Cboldsymbol%7Bw%7D-+%5Cboldsymbol%7By%7D%29)，求微分，使用矩阵乘法、转置等法则：![dl = (Xd\boldsymbol{w})^T(X\boldsymbol{w}-\boldsymbol{y})+(X\boldsymbol{w}-\boldsymbol{y})^T(Xd\boldsymbol{w}) = 2(X\boldsymbol{w}-\boldsymbol{y})^TXd\boldsymbol{w}](https://www.zhihu.com/equation?tex=dl+%3D+%28Xd%5Cboldsymbol%7Bw%7D%29%5ET%28X%5Cboldsymbol%7Bw%7D-%5Cboldsymbol%7By%7D%29%2B%28X%5Cboldsymbol%7Bw%7D-%5Cboldsymbol%7By%7D%29%5ET%28Xd%5Cboldsymbol%7Bw%7D%29+%3D+2%28X%5Cboldsymbol%7Bw%7D-%5Cboldsymbol%7By%7D%29%5ETXd%5Cboldsymbol%7Bw%7D)。对照导数与微分的联系![dl = \frac{\partial l}{\partial \boldsymbol{w}}^Td\boldsymbol{w}](https://www.zhihu.com/equation?tex=dl+%3D+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Bw%7D%7D%5ETd%5Cboldsymbol%7Bw%7D)，得到![\frac{\partial l}{\partial \boldsymbol{w}} = 2X^T(X\boldsymbol{w}-\boldsymbol{y})](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Bw%7D%7D+%3D+2X%5ET%28X%5Cboldsymbol%7Bw%7D-%5Cboldsymbol%7By%7D%29)。![\frac{\partial l}{\partial \boldsymbol{w}}=0](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Bw%7D%7D%3D0)即![X^TX\boldsymbol{w} = X^T\boldsymbol{y}](https://www.zhihu.com/equation?tex=X%5ETX%5Cboldsymbol%7Bw%7D+%3D+X%5ET%5Cboldsymbol%7By%7D)，得到![\boldsymbol{w}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bw%7D)的最小二乘估计为![\boldsymbol{w} = (X^TX)^{-1}X^T\boldsymbol{y}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bw%7D+%3D+%28X%5ETX%29%5E%7B-1%7DX%5ET%5Cboldsymbol%7By%7D)。



例5【方差的最大似然估计】：样本![\boldsymbol{x}_1,\dots, \boldsymbol{x}_N \sim \mathcal{N}(\boldsymbol{\mu}, \Sigma)](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bx%7D_1%2C%5Cdots%2C+%5Cboldsymbol%7Bx%7D_N+%5Csim+%5Cmathcal%7BN%7D%28%5Cboldsymbol%7B%5Cmu%7D%2C+%5CSigma%29)，求方差![\Sigma](https://www.zhihu.com/equation?tex=%5CSigma)的最大似然估计。写成数学式是：![l = \log|\Sigma|+\frac{1}{N}\sum_{i=1}^N(\boldsymbol{x}_i-\boldsymbol{\bar{x}})^T\Sigma^{-1}(\boldsymbol{x}_i-\boldsymbol{\bar{x}})](https://www.zhihu.com/equation?tex=l+%3D+%5Clog%7C%5CSigma%7C%2B%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5EN%28%5Cboldsymbol%7Bx%7D_i-%5Cboldsymbol%7B%5Cbar%7Bx%7D%7D%29%5ET%5CSigma%5E%7B-1%7D%28%5Cboldsymbol%7Bx%7D_i-%5Cboldsymbol%7B%5Cbar%7Bx%7D%7D%29)，求![\frac{\partial l }{\partial \Sigma}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l+%7D%7B%5Cpartial+%5CSigma%7D)的零点。其中![\boldsymbol{x}_i](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bx%7D_i)是![m\times 1](https://www.zhihu.com/equation?tex=m%5Ctimes+1)列向量，![\bar{\boldsymbol{x}}=\frac{1}{N}\sum_{i=1}^N \boldsymbol{x}_i](https://www.zhihu.com/equation?tex=%5Cbar%7B%5Cboldsymbol%7Bx%7D%7D%3D%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5EN+%5Cboldsymbol%7Bx%7D_i)是样本均值，![\Sigma](https://www.zhihu.com/equation?tex=%5CSigma)是![m\times m](https://www.zhihu.com/equation?tex=m%5Ctimes+m)对称正定矩阵，![l](https://www.zhihu.com/equation?tex=l)是标量，log表示自然对数。

解：首先求微分，使用矩阵乘法、行列式、逆等运算法则，第一项是![d\log|\Sigma| = |\Sigma|^{-1}d|\Sigma| = \text{tr}(\Sigma^{-1}d\Sigma)](https://www.zhihu.com/equation?tex=d%5Clog%7C%5CSigma%7C+%3D+%7C%5CSigma%7C%5E%7B-1%7Dd%7C%5CSigma%7C+%3D+%5Ctext%7Btr%7D%28%5CSigma%5E%7B-1%7Dd%5CSigma%29)，第二项是![\frac{1}{N}\sum_{i=1}^N(\boldsymbol{x}_i-\boldsymbol{\bar{x}})^Td\Sigma^{-1}(\boldsymbol{x}_i-\boldsymbol{\bar{x}}) = -\frac{1}{N}\sum_{i=1}^N(\boldsymbol{x}_i-\boldsymbol{\bar{x}})^T\Sigma^{-1}d\Sigma\Sigma^{-1}(\boldsymbol{x}_i-\boldsymbol{\bar{x}})](https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5EN%28%5Cboldsymbol%7Bx%7D_i-%5Cboldsymbol%7B%5Cbar%7Bx%7D%7D%29%5ETd%5CSigma%5E%7B-1%7D%28%5Cboldsymbol%7Bx%7D_i-%5Cboldsymbol%7B%5Cbar%7Bx%7D%7D%29+%3D+-%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5EN%28%5Cboldsymbol%7Bx%7D_i-%5Cboldsymbol%7B%5Cbar%7Bx%7D%7D%29%5ET%5CSigma%5E%7B-1%7Dd%5CSigma%5CSigma%5E%7B-1%7D%28%5Cboldsymbol%7Bx%7D_i-%5Cboldsymbol%7B%5Cbar%7Bx%7D%7D%29)。再给第二项套上迹做交换：![ \text{tr}\left(\frac{1}{N}\sum_{i=1}^N(\boldsymbol{x}_i-\boldsymbol{\bar{x}})^T\Sigma^{-1}d\Sigma\Sigma^{-1}(\boldsymbol{x}_i-\boldsymbol{\bar{x}})\right) ](https://www.zhihu.com/equation?tex=+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5EN%28%5Cboldsymbol%7Bx%7D_i-%5Cboldsymbol%7B%5Cbar%7Bx%7D%7D%29%5ET%5CSigma%5E%7B-1%7Dd%5CSigma%5CSigma%5E%7B-1%7D%28%5Cboldsymbol%7Bx%7D_i-%5Cboldsymbol%7B%5Cbar%7Bx%7D%7D%29%5Cright%29+)![= \frac{1}{N} \sum_{i=1}^N \text{tr}((\boldsymbol{x}_i-\boldsymbol{\bar{x}})^T\Sigma^{-1} d\Sigma \Sigma^{-1}(\boldsymbol{x}_i-\boldsymbol{\bar{x}}))](https://www.zhihu.com/equation?tex=%3D+%5Cfrac%7B1%7D%7BN%7D+%5Csum_%7Bi%3D1%7D%5EN+%5Ctext%7Btr%7D%28%28%5Cboldsymbol%7Bx%7D_i-%5Cboldsymbol%7B%5Cbar%7Bx%7D%7D%29%5ET%5CSigma%5E%7B-1%7D+d%5CSigma+%5CSigma%5E%7B-1%7D%28%5Cboldsymbol%7Bx%7D_i-%5Cboldsymbol%7B%5Cbar%7Bx%7D%7D%29%29)![= \frac{1}{N}\sum_{i=1}^N\text{tr}\left(\Sigma^{-1}(\boldsymbol{x}_i-\boldsymbol{\bar{x}})(\boldsymbol{x}_i-\boldsymbol{\bar{x}})^T\Sigma^{-1}d\Sigma\right)=\text{tr}(\Sigma^{-1}S\Sigma^{-1}d\Sigma)](https://www.zhihu.com/equation?tex=%3D+%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5EN%5Ctext%7Btr%7D%5Cleft%28%5CSigma%5E%7B-1%7D%28%5Cboldsymbol%7Bx%7D_i-%5Cboldsymbol%7B%5Cbar%7Bx%7D%7D%29%28%5Cboldsymbol%7Bx%7D_i-%5Cboldsymbol%7B%5Cbar%7Bx%7D%7D%29%5ET%5CSigma%5E%7B-1%7Dd%5CSigma%5Cright%29%3D%5Ctext%7Btr%7D%28%5CSigma%5E%7B-1%7DS%5CSigma%5E%7B-1%7Dd%5CSigma%29)，其中先交换迹与求和，然后将 ![\Sigma^{-1} (\boldsymbol{x}_i-\boldsymbol{\bar{x}})](https://www.zhihu.com/equation?tex=%5CSigma%5E%7B-1%7D+%28%5Cboldsymbol%7Bx%7D_i-%5Cboldsymbol%7B%5Cbar%7Bx%7D%7D%29)交换到左边，最后再交换迹与求和，并定义![S = \frac{1}{N}\sum_{i=1}^N(\boldsymbol{x}_i-\boldsymbol{\bar{x}})(\boldsymbol{x}_i-\boldsymbol{\bar{x}})^T](https://www.zhihu.com/equation?tex=S+%3D+%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bi%3D1%7D%5EN%28%5Cboldsymbol%7Bx%7D_i-%5Cboldsymbol%7B%5Cbar%7Bx%7D%7D%29%28%5Cboldsymbol%7Bx%7D_i-%5Cboldsymbol%7B%5Cbar%7Bx%7D%7D%29%5ET)为样本方差矩阵。得到![dl = \text{tr}\left(\left(\Sigma^{-1}-\Sigma^{-1}S\Sigma^{-1}\right)d\Sigma\right)](https://www.zhihu.com/equation?tex=dl+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cleft%28%5CSigma%5E%7B-1%7D-%5CSigma%5E%7B-1%7DS%5CSigma%5E%7B-1%7D%5Cright%29d%5CSigma%5Cright%29)。对照导数与微分的联系，有![\frac{\partial l }{\partial \Sigma}=(\Sigma^{-1}-\Sigma^{-1}S\Sigma^{-1})^T](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l+%7D%7B%5Cpartial+%5CSigma%7D%3D%28%5CSigma%5E%7B-1%7D-%5CSigma%5E%7B-1%7DS%5CSigma%5E%7B-1%7D%29%5ET)，其零点即![\Sigma](https://www.zhihu.com/equation?tex=%5CSigma)的最大似然估计为![\Sigma = S](https://www.zhihu.com/equation?tex=%5CSigma+%3D+S)。



例6【多元logistic回归】：![l = -\boldsymbol{y}^T\log\text{softmax}(W\boldsymbol{x})](https://www.zhihu.com/equation?tex=l+%3D+-%5Cboldsymbol%7By%7D%5ET%5Clog%5Ctext%7Bsoftmax%7D%28W%5Cboldsymbol%7Bx%7D%29)，求![\frac{\partial l}{\partial W}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+W%7D)。其中![\boldsymbol{y}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7By%7D)是除一个元素为1外其它元素为0的![m×1](https://www.zhihu.com/equation?tex=m%C3%971)列向量，![W](https://www.zhihu.com/equation?tex=W)是![m\times n](https://www.zhihu.com/equation?tex=m%5Ctimes+n)矩阵，![\boldsymbol{x}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bx%7D)是![n×1](https://www.zhihu.com/equation?tex=n%C3%971)列向量，![l](https://www.zhihu.com/equation?tex=l)是标量；log表示自然对数，![\text{softmax}(\boldsymbol{a}) = \frac{\exp(\boldsymbol{a})}{\boldsymbol{1}^T\exp(\boldsymbol{a})}](https://www.zhihu.com/equation?tex=%5Ctext%7Bsoftmax%7D%28%5Cboldsymbol%7Ba%7D%29+%3D+%5Cfrac%7B%5Cexp%28%5Cboldsymbol%7Ba%7D%29%7D%7B%5Cboldsymbol%7B1%7D%5ET%5Cexp%28%5Cboldsymbol%7Ba%7D%29%7D)，其中![\exp(\boldsymbol{a})](https://www.zhihu.com/equation?tex=%5Cexp%28%5Cboldsymbol%7Ba%7D%29)表示逐元素求指数，![\boldsymbol{1}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7B1%7D)代表全1向量。

解1：首先将softmax函数代入并写成![l = -\boldsymbol{y}^T \left(\log (\exp(W\boldsymbol{x}))-\boldsymbol{1}\log(\boldsymbol{1}^T\exp(W\boldsymbol{x}))\right) = -\boldsymbol{y}^TW\boldsymbol{x} + \log(\boldsymbol{1}^T\exp(W\boldsymbol{x}))](https://www.zhihu.com/equation?tex=l+%3D+-%5Cboldsymbol%7By%7D%5ET+%5Cleft%28%5Clog+%28%5Cexp%28W%5Cboldsymbol%7Bx%7D%29%29-%5Cboldsymbol%7B1%7D%5Clog%28%5Cboldsymbol%7B1%7D%5ET%5Cexp%28W%5Cboldsymbol%7Bx%7D%29%29%5Cright%29+%3D+-%5Cboldsymbol%7By%7D%5ETW%5Cboldsymbol%7Bx%7D+%2B+%5Clog%28%5Cboldsymbol%7B1%7D%5ET%5Cexp%28W%5Cboldsymbol%7Bx%7D%29%29)，这里要注意逐元素log满足等式![\log(\boldsymbol{u}/c) = \log(\boldsymbol{u}) - \boldsymbol{1}\log(c)](https://www.zhihu.com/equation?tex=%5Clog%28%5Cboldsymbol%7Bu%7D%2Fc%29+%3D+%5Clog%28%5Cboldsymbol%7Bu%7D%29+-+%5Cboldsymbol%7B1%7D%5Clog%28c%29)，以及![\boldsymbol{y}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7By%7D)满足![\boldsymbol{y}^T \boldsymbol{1} = 1](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7By%7D%5ET+%5Cboldsymbol%7B1%7D+%3D+1)。求微分，使用矩阵乘法、逐元素函数等法则：![dl =- \boldsymbol{y}^TdW\boldsymbol{x}+\frac{\boldsymbol{1}^T\left(\exp(W\boldsymbol{x})\odot(dW\boldsymbol{x})\right)}{\boldsymbol{1}^T\exp(W\boldsymbol{x})}](https://www.zhihu.com/equation?tex=dl+%3D-+%5Cboldsymbol%7By%7D%5ETdW%5Cboldsymbol%7Bx%7D%2B%5Cfrac%7B%5Cboldsymbol%7B1%7D%5ET%5Cleft%28%5Cexp%28W%5Cboldsymbol%7Bx%7D%29%5Codot%28dW%5Cboldsymbol%7Bx%7D%29%5Cright%29%7D%7B%5Cboldsymbol%7B1%7D%5ET%5Cexp%28W%5Cboldsymbol%7Bx%7D%29%7D)。再套上迹并做交换，注意可化简![\boldsymbol{1}^T\left(\exp(W\boldsymbol{x})\odot(dW\boldsymbol{x})\right) = \exp(W\boldsymbol{x})^TdW\boldsymbol{x}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7B1%7D%5ET%5Cleft%28%5Cexp%28W%5Cboldsymbol%7Bx%7D%29%5Codot%28dW%5Cboldsymbol%7Bx%7D%29%5Cright%29+%3D+%5Cexp%28W%5Cboldsymbol%7Bx%7D%29%5ETdW%5Cboldsymbol%7Bx%7D)，这是根据等式![\boldsymbol{1}^T (\boldsymbol{u}\odot \boldsymbol{v}) = \boldsymbol{u}^T \boldsymbol{v}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7B1%7D%5ET+%28%5Cboldsymbol%7Bu%7D%5Codot+%5Cboldsymbol%7Bv%7D%29+%3D+%5Cboldsymbol%7Bu%7D%5ET+%5Cboldsymbol%7Bv%7D)，故![dl = \text{tr}\left(-\boldsymbol{y}^TdW\boldsymbol{x}+\frac{\exp(W\boldsymbol{x})^TdW\boldsymbol{x}}{\boldsymbol{1}^T\exp(W\boldsymbol{x})}\right) =\text{tr}(-\boldsymbol{y}^TdW\boldsymbol{x}+\text{softmax}(W\boldsymbol{x})^TdW\boldsymbol{x}) = \text{tr}(\boldsymbol{x}(\text{softmax}(W\boldsymbol{x})-\boldsymbol{y})^TdW)](https://www.zhihu.com/equation?tex=dl+%3D+%5Ctext%7Btr%7D%5Cleft%28-%5Cboldsymbol%7By%7D%5ETdW%5Cboldsymbol%7Bx%7D%2B%5Cfrac%7B%5Cexp%28W%5Cboldsymbol%7Bx%7D%29%5ETdW%5Cboldsymbol%7Bx%7D%7D%7B%5Cboldsymbol%7B1%7D%5ET%5Cexp%28W%5Cboldsymbol%7Bx%7D%29%7D%5Cright%29+%3D%5Ctext%7Btr%7D%28-%5Cboldsymbol%7By%7D%5ETdW%5Cboldsymbol%7Bx%7D%2B%5Ctext%7Bsoftmax%7D%28W%5Cboldsymbol%7Bx%7D%29%5ETdW%5Cboldsymbol%7Bx%7D%29+%3D+%5Ctext%7Btr%7D%28%5Cboldsymbol%7Bx%7D%28%5Ctext%7Bsoftmax%7D%28W%5Cboldsymbol%7Bx%7D%29-%5Cboldsymbol%7By%7D%29%5ETdW%29)。对照导数与微分的联系，得到![\frac{\partial l}{\partial W}= (\text{softmax}(W\boldsymbol{x})-\boldsymbol{y})\boldsymbol{x}^T](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+W%7D%3D+%28%5Ctext%7Bsoftmax%7D%28W%5Cboldsymbol%7Bx%7D%29-%5Cboldsymbol%7By%7D%29%5Cboldsymbol%7Bx%7D%5ET)。

解2：定义![\boldsymbol{a} = W\boldsymbol{x}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Ba%7D+%3D+W%5Cboldsymbol%7Bx%7D)，则![l = -\boldsymbol{y}^T\log\text{softmax}(\boldsymbol{a}) ](https://www.zhihu.com/equation?tex=l+%3D+-%5Cboldsymbol%7By%7D%5ET%5Clog%5Ctext%7Bsoftmax%7D%28%5Cboldsymbol%7Ba%7D%29+)，先同上求出![\frac{\partial l}{\partial \boldsymbol{a}} = \text{softmax}(\boldsymbol{a})-\boldsymbol{y} ](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Ba%7D%7D+%3D+%5Ctext%7Bsoftmax%7D%28%5Cboldsymbol%7Ba%7D%29-%5Cboldsymbol%7By%7D+)，再利用复合法则：![dl = \text{tr}\left(\frac{\partial l}{\partial \boldsymbol{a}}^Td\boldsymbol{a}\right) = \text{tr}\left(\frac{\partial l}{\partial \boldsymbol{a}}^TdW \boldsymbol{x}\right) = \text{tr}\left(\boldsymbol{x}\frac{\partial l}{\partial \boldsymbol{a}}^TdW\right)](https://www.zhihu.com/equation?tex=dl+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Ba%7D%7D%5ETd%5Cboldsymbol%7Ba%7D%5Cright%29+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Ba%7D%7D%5ETdW+%5Cboldsymbol%7Bx%7D%5Cright%29+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cboldsymbol%7Bx%7D%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Ba%7D%7D%5ETdW%5Cright%29)，得到![\frac{\partial l}{\partial W}= \frac{\partial l}{\partial\boldsymbol{a}}\boldsymbol{x}^T](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+W%7D%3D+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Ba%7D%7D%5Cboldsymbol%7Bx%7D%5ET)。



最后一例留给经典的神经网络。神经网络的求导术是学术史上的重要成果，还有个专门的名字叫做BP算法，我相信如今很多人在初次推导BP算法时也会颇费一番脑筋，事实上使用矩阵求导术来推导并不复杂。为简化起见，我们推导二层神经网络的BP算法。

例7【二层神经网络】：![l = -\boldsymbol{y}^T\log\text{softmax}(W_2\sigma(W_1\boldsymbol{x}))](https://www.zhihu.com/equation?tex=l+%3D+-%5Cboldsymbol%7By%7D%5ET%5Clog%5Ctext%7Bsoftmax%7D%28W_2%5Csigma%28W_1%5Cboldsymbol%7Bx%7D%29%29)，求![\frac{\partial l}{\partial W_1}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+W_1%7D)和![\frac{\partial l}{\partial W_2}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+W_2%7D)。其中![\boldsymbol{y}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7By%7D)是除一个元素为1外其它元素为0的的![m×1](https://www.zhihu.com/equation?tex=m%C3%971)列向量，![W_2](https://www.zhihu.com/equation?tex=W_2)是![m\times p](https://www.zhihu.com/equation?tex=m%5Ctimes+p)矩阵，![W_1](https://www.zhihu.com/equation?tex=W_1)是![p \times n](https://www.zhihu.com/equation?tex=p+%5Ctimes+n)矩阵，![\boldsymbol{x}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bx%7D)是![n×1](https://www.zhihu.com/equation?tex=n%C3%971)列向量，![l](https://www.zhihu.com/equation?tex=l)是标量；log表示自然对数，![\text{softmax}(\boldsymbol{a}) = \frac{\exp(\boldsymbol{a})}{\boldsymbol{1}^T\exp(\boldsymbol{a})}](https://www.zhihu.com/equation?tex=%5Ctext%7Bsoftmax%7D%28%5Cboldsymbol%7Ba%7D%29+%3D+%5Cfrac%7B%5Cexp%28%5Cboldsymbol%7Ba%7D%29%7D%7B%5Cboldsymbol%7B1%7D%5ET%5Cexp%28%5Cboldsymbol%7Ba%7D%29%7D)同上，![\sigma](https://www.zhihu.com/equation?tex=%5Csigma)是逐元素sigmoid函数![\sigma(a) = \frac{1}{1+\exp(-a)}](https://www.zhihu.com/equation?tex=%5Csigma%28a%29+%3D+%5Cfrac%7B1%7D%7B1%2B%5Cexp%28-a%29%7D)。

解：定义![\boldsymbol{a}_1=W_1\boldsymbol{x}](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Ba%7D_1%3DW_1%5Cboldsymbol%7Bx%7D)，![\boldsymbol{h}_1 = \sigma(\boldsymbol{a}_1)](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bh%7D_1+%3D+%5Csigma%28%5Cboldsymbol%7Ba%7D_1%29)，![\boldsymbol{a}_2 = W_2 \boldsymbol{h}_1](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Ba%7D_2+%3D+W_2+%5Cboldsymbol%7Bh%7D_1)，则![l =-\boldsymbol{y}^T\log\text{softmax}(\boldsymbol{a}_2)](https://www.zhihu.com/equation?tex=l+%3D-%5Cboldsymbol%7By%7D%5ET%5Clog%5Ctext%7Bsoftmax%7D%28%5Cboldsymbol%7Ba%7D_2%29)。在前例中已求出![\frac{\partial l}{\partial \boldsymbol{a}_2} = \text{softmax}(\boldsymbol{a}_2)-\boldsymbol{y} ](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Ba%7D_2%7D+%3D+%5Ctext%7Bsoftmax%7D%28%5Cboldsymbol%7Ba%7D_2%29-%5Cboldsymbol%7By%7D+)。使用复合法则，![dl = \text{tr}\left(\frac{\partial l}{\partial \boldsymbol{a}_2}^Td\boldsymbol{a}_2\right) = \text{tr}\left(\frac{\partial l}{\partial \boldsymbol{a}_2}^TdW_2 \boldsymbol{h}_1\right) + \underbrace{ \text{tr}\left(\frac{\partial l}{\partial \boldsymbol{a}_2}^TW_2 d\boldsymbol{h}_1\right)}_{dl_2}](https://www.zhihu.com/equation?tex=dl+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Ba%7D_2%7D%5ETd%5Cboldsymbol%7Ba%7D_2%5Cright%29+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Ba%7D_2%7D%5ETdW_2+%5Cboldsymbol%7Bh%7D_1%5Cright%29+%2B+%5Cunderbrace%7B+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Ba%7D_2%7D%5ETW_2+d%5Cboldsymbol%7Bh%7D_1%5Cright%29%7D_%7Bdl_2%7D)，使用矩阵乘法交换的迹技巧从第一项得到![\frac{\partial l}{\partial W_2}= \frac{\partial l}{\partial\boldsymbol{a}_2}\boldsymbol{h}_1^T](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+W_2%7D%3D+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Ba%7D_2%7D%5Cboldsymbol%7Bh%7D_1%5ET)，从第二项得到![\frac{\partial l}{\partial \boldsymbol{h}_1}= W_2^T\frac{\partial l}{\partial\boldsymbol{a}_2}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Bh%7D_1%7D%3D+W_2%5ET%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Ba%7D_2%7D)。接下来对第二项继续使用复合法则来求![\frac{\partial l}{\partial \boldsymbol{a}_1}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Ba%7D_1%7D)，并利用矩阵乘法和逐元素乘法交换的迹技巧：![dl_2 = \text{tr}\left(\frac{\partial l}{\partial\boldsymbol{h}_1}^Td\boldsymbol{h}_1\right) = \text{tr}\left(\frac{\partial l}{\partial\boldsymbol{h}_1}^T(\sigma'(\boldsymbol{a}_1)\odot d\boldsymbol{a}_1)\right) = \text{tr}\left(\left(\frac{\partial l}{\partial\boldsymbol{h}_1}\odot \sigma'(\boldsymbol{a}_1)\right)^Td\boldsymbol{a}_1\right)](https://www.zhihu.com/equation?tex=dl_2+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Bh%7D_1%7D%5ETd%5Cboldsymbol%7Bh%7D_1%5Cright%29+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Bh%7D_1%7D%5ET%28%5Csigma%27%28%5Cboldsymbol%7Ba%7D_1%29%5Codot+d%5Cboldsymbol%7Ba%7D_1%29%5Cright%29+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cleft%28%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Bh%7D_1%7D%5Codot+%5Csigma%27%28%5Cboldsymbol%7Ba%7D_1%29%5Cright%29%5ETd%5Cboldsymbol%7Ba%7D_1%5Cright%29)，得到![\frac{\partial l}{\partial \boldsymbol{a}_1}= \frac{\partial l}{\partial\boldsymbol{h}_1}\odot\sigma'(\boldsymbol{a}_1)](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Ba%7D_1%7D%3D+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Bh%7D_1%7D%5Codot%5Csigma%27%28%5Cboldsymbol%7Ba%7D_1%29)。为求![\frac{\partial l}{\partial W_1}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+W_1%7D)，再用一次复合法则：![dl_2 = \text{tr}\left(\frac{\partial l}{\partial\boldsymbol{a}_1}^Td\boldsymbol{a}_1\right) = \text{tr}\left(\frac{\partial l}{\partial\boldsymbol{a}_1}^TdW_1\boldsymbol{x}\right) = \text{tr}\left(\boldsymbol{x}\frac{\partial l}{\partial\boldsymbol{a}_1}^TdW_1\right)](https://www.zhihu.com/equation?tex=dl_2+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Ba%7D_1%7D%5ETd%5Cboldsymbol%7Ba%7D_1%5Cright%29+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Ba%7D_1%7D%5ETdW_1%5Cboldsymbol%7Bx%7D%5Cright%29+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cboldsymbol%7Bx%7D%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Ba%7D_1%7D%5ETdW_1%5Cright%29)，得到![\frac{\partial l}{\partial W_1}= \frac{\partial l}{\partial\boldsymbol{a}_1}\boldsymbol{x}^T](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+W_1%7D%3D+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Ba%7D_1%7D%5Cboldsymbol%7Bx%7D%5ET)。

推广：样本![(\boldsymbol{x}_1, y_1), \dots, (\boldsymbol{x}_N,y_N)](https://www.zhihu.com/equation?tex=%28%5Cboldsymbol%7Bx%7D_1%2C+y_1%29%2C+%5Cdots%2C+%28%5Cboldsymbol%7Bx%7D_N%2Cy_N%29)，![l = -\sum_{i=1}^N \boldsymbol{y}_i^T\log\text{softmax}(W_2\sigma(W_1\boldsymbol{x}_i + \boldsymbol{b}_1) + \boldsymbol{b}_2)](https://www.zhihu.com/equation?tex=l+%3D+-%5Csum_%7Bi%3D1%7D%5EN+%5Cboldsymbol%7By%7D_i%5ET%5Clog%5Ctext%7Bsoftmax%7D%28W_2%5Csigma%28W_1%5Cboldsymbol%7Bx%7D_i+%2B+%5Cboldsymbol%7Bb%7D_1%29+%2B+%5Cboldsymbol%7Bb%7D_2%29)，其中![\boldsymbol{b}_1](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bb%7D_1)是![p \times 1](https://www.zhihu.com/equation?tex=p+%5Ctimes+1)列向量，![\boldsymbol{b}_2](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bb%7D_2)是![m\times 1](https://www.zhihu.com/equation?tex=m%5Ctimes+1)列向量，其余定义同上。

解1：定义![\boldsymbol{a}_{1,i} = W_1 \boldsymbol{x}_i + \boldsymbol{b}_1](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Ba%7D_%7B1%2Ci%7D+%3D+W_1+%5Cboldsymbol%7Bx%7D_i+%2B+%5Cboldsymbol%7Bb%7D_1)，![\boldsymbol{h}_{1,i} = \sigma(\boldsymbol{a}_{1,i})](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Bh%7D_%7B1%2Ci%7D+%3D+%5Csigma%28%5Cboldsymbol%7Ba%7D_%7B1%2Ci%7D%29)，![\boldsymbol{a}_{2,i} = W_2\boldsymbol{h}_{1,i} + \boldsymbol{b}_2](https://www.zhihu.com/equation?tex=%5Cboldsymbol%7Ba%7D_%7B2%2Ci%7D+%3D+W_2%5Cboldsymbol%7Bh%7D_%7B1%2Ci%7D+%2B+%5Cboldsymbol%7Bb%7D_2)，则![l = -\sum_{i=1}^N \boldsymbol{y}_i^T \log \text{softmax}(\boldsymbol{a}_{2,i})](https://www.zhihu.com/equation?tex=l+%3D+-%5Csum_%7Bi%3D1%7D%5EN+%5Cboldsymbol%7By%7D_i%5ET+%5Clog+%5Ctext%7Bsoftmax%7D%28%5Cboldsymbol%7Ba%7D_%7B2%2Ci%7D%29)。先同上可求出![\frac{\partial l}{\partial \boldsymbol{a}_{2,i}} = \text{softmax}(\boldsymbol{a}_{2,i})-\boldsymbol{y}_i ](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Ba%7D_%7B2%2Ci%7D%7D+%3D+%5Ctext%7Bsoftmax%7D%28%5Cboldsymbol%7Ba%7D_%7B2%2Ci%7D%29-%5Cboldsymbol%7By%7D_i+)。使用复合法则，![dl = \text{tr}\left(\sum_{i=1}^N\frac{\partial l}{\partial \boldsymbol{a}_{2,i}}^T d \boldsymbol{a}_{2,i}\right) = \text{tr}\left( \sum_{i=1}^N \frac{\partial l}{\partial \boldsymbol{a}_{2,i}}^T dW_2 \boldsymbol{h}_{1,i}\right) + \underbrace{\text{tr}\left( \sum_{i=1}^N \frac{\partial l}{\partial \boldsymbol{a}_{2,i}}^T W_2 d\boldsymbol{h}_{1,i}\right)}_{dl_2} + \text{tr}\left( \sum_{i=1}^N \frac{\partial l}{\partial \boldsymbol{a}_{2,i}}^T d \boldsymbol{b}_2\right)](https://www.zhihu.com/equation?tex=dl+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Csum_%7Bi%3D1%7D%5EN%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Ba%7D_%7B2%2Ci%7D%7D%5ET+d+%5Cboldsymbol%7Ba%7D_%7B2%2Ci%7D%5Cright%29+%3D+%5Ctext%7Btr%7D%5Cleft%28+%5Csum_%7Bi%3D1%7D%5EN+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Ba%7D_%7B2%2Ci%7D%7D%5ET+dW_2+%5Cboldsymbol%7Bh%7D_%7B1%2Ci%7D%5Cright%29+%2B+%5Cunderbrace%7B%5Ctext%7Btr%7D%5Cleft%28+%5Csum_%7Bi%3D1%7D%5EN+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Ba%7D_%7B2%2Ci%7D%7D%5ET+W_2+d%5Cboldsymbol%7Bh%7D_%7B1%2Ci%7D%5Cright%29%7D_%7Bdl_2%7D+%2B+%5Ctext%7Btr%7D%5Cleft%28+%5Csum_%7Bi%3D1%7D%5EN+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Ba%7D_%7B2%2Ci%7D%7D%5ET+d+%5Cboldsymbol%7Bb%7D_2%5Cright%29)，从第一项得到得到![\frac{\partial l}{\partial W_2}= \sum_{i=1}^N \frac{\partial l}{\partial\boldsymbol{a}_{2,i}}\boldsymbol{h}_{1,i}^T](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+W_2%7D%3D+%5Csum_%7Bi%3D1%7D%5EN+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Ba%7D_%7B2%2Ci%7D%7D%5Cboldsymbol%7Bh%7D_%7B1%2Ci%7D%5ET)，从第二项得到![\frac{\partial l}{\partial \boldsymbol{h}_{1,i}}= W_2^T\frac{\partial l}{\partial\boldsymbol{a}_{2,i}}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Bh%7D_%7B1%2Ci%7D%7D%3D+W_2%5ET%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Ba%7D_%7B2%2Ci%7D%7D)，从第三项得到到![\frac{\partial l}{\partial \boldsymbol{b}_2}= \sum_{i=1}^N \frac{\partial l}{\partial\boldsymbol{a}_{2,i}}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Bb%7D_2%7D%3D+%5Csum_%7Bi%3D1%7D%5EN+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Ba%7D_%7B2%2Ci%7D%7D)。接下来对第二项继续使用复合法则，得到![\frac{\partial l}{\partial \boldsymbol{a}_{1,i}}= \frac{\partial l}{\partial\boldsymbol{h}_{1,i}}\odot\sigma'(\boldsymbol{a}_{1,i})](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Ba%7D_%7B1%2Ci%7D%7D%3D+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Bh%7D_%7B1%2Ci%7D%7D%5Codot%5Csigma%27%28%5Cboldsymbol%7Ba%7D_%7B1%2Ci%7D%29)。为求![\frac{\partial l}{\partial W_1}, \frac{\partial l}{\partial \boldsymbol{b}_1}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+W_1%7D%2C+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Bb%7D_1%7D)，再用一次复合法则：![dl_2 = \text{tr}\left(\sum_{i=1}^N \frac{\partial l}{\partial\boldsymbol{a}_{1,i}}^Td\boldsymbol{a}_{1,i}\right) = \text{tr}\left(\sum_{i=1}^N \frac{\partial l}{\partial\boldsymbol{a}_{1,i}}^TdW_1\boldsymbol{x}_i\right) + \text{tr}\left(\sum_{i=1}^N \frac{\partial l}{\partial\boldsymbol{a}_{1,i}}^Td\boldsymbol{b}_1\right)](https://www.zhihu.com/equation?tex=dl_2+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Csum_%7Bi%3D1%7D%5EN+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Ba%7D_%7B1%2Ci%7D%7D%5ETd%5Cboldsymbol%7Ba%7D_%7B1%2Ci%7D%5Cright%29+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Csum_%7Bi%3D1%7D%5EN+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Ba%7D_%7B1%2Ci%7D%7D%5ETdW_1%5Cboldsymbol%7Bx%7D_i%5Cright%29+%2B+%5Ctext%7Btr%7D%5Cleft%28%5Csum_%7Bi%3D1%7D%5EN+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Ba%7D_%7B1%2Ci%7D%7D%5ETd%5Cboldsymbol%7Bb%7D_1%5Cright%29)，得到![\frac{\partial l}{\partial W_1}= \sum_{i=1}^N \frac{\partial l}{\partial\boldsymbol{a}_{1,i}}\boldsymbol{x}_i^T](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+W_1%7D%3D+%5Csum_%7Bi%3D1%7D%5EN+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Ba%7D_%7B1%2Ci%7D%7D%5Cboldsymbol%7Bx%7D_i%5ET)，![\frac{\partial l}{\partial \boldsymbol{b}_1}= \sum_{i=1}^N \frac{\partial l}{\partial\boldsymbol{a}_{1,i}}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Bb%7D_1%7D%3D+%5Csum_%7Bi%3D1%7D%5EN+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial%5Cboldsymbol%7Ba%7D_%7B1%2Ci%7D%7D)。

解2：可以用矩阵来表示N个样本，以简化形式。定义![X = [\boldsymbol{x}_1, \cdots, \boldsymbol{x}_N]](https://www.zhihu.com/equation?tex=X+%3D+%5B%5Cboldsymbol%7Bx%7D_1%2C+%5Ccdots%2C+%5Cboldsymbol%7Bx%7D_N%5D)，![A_1 = [\boldsymbol{a}_{1,1},\cdots,\boldsymbol{a}_{1,N}] =W_1 X + \boldsymbol{b}_1 \boldsymbol{1}^T](https://www.zhihu.com/equation?tex=A_1+%3D+%5B%5Cboldsymbol%7Ba%7D_%7B1%2C1%7D%2C%5Ccdots%2C%5Cboldsymbol%7Ba%7D_%7B1%2CN%7D%5D+%3DW_1+X+%2B+%5Cboldsymbol%7Bb%7D_1+%5Cboldsymbol%7B1%7D%5ET)，![H_1 = [\boldsymbol{h}_{1,1}, \cdots, \boldsymbol{h}_{1,N}] = \sigma(A_1)](https://www.zhihu.com/equation?tex=H_1+%3D+%5B%5Cboldsymbol%7Bh%7D_%7B1%2C1%7D%2C+%5Ccdots%2C+%5Cboldsymbol%7Bh%7D_%7B1%2CN%7D%5D+%3D+%5Csigma%28A_1%29)，![A_2 = [\boldsymbol{a}_{2,1},\cdots,\boldsymbol{a}_{2,N}] = W_2 H_1 + \boldsymbol{b}_2 \boldsymbol{1}^T](https://www.zhihu.com/equation?tex=A_2+%3D+%5B%5Cboldsymbol%7Ba%7D_%7B2%2C1%7D%2C%5Ccdots%2C%5Cboldsymbol%7Ba%7D_%7B2%2CN%7D%5D+%3D+W_2+H_1+%2B+%5Cboldsymbol%7Bb%7D_2+%5Cboldsymbol%7B1%7D%5ET)，注意这里使用全1向量来扩展维度。先同上求出![\frac{\partial l}{\partial A_2} = [\text{softmax}(\boldsymbol{a}_{2,1})-\boldsymbol{y}_1, \cdots, \text{softmax}(\boldsymbol{a}_{2,N})-\boldsymbol{y}_N] ](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+A_2%7D+%3D+%5B%5Ctext%7Bsoftmax%7D%28%5Cboldsymbol%7Ba%7D_%7B2%2C1%7D%29-%5Cboldsymbol%7By%7D_1%2C+%5Ccdots%2C+%5Ctext%7Bsoftmax%7D%28%5Cboldsymbol%7Ba%7D_%7B2%2CN%7D%29-%5Cboldsymbol%7By%7D_N%5D+)。使用复合法则，![dl = \text{tr}\left(\frac{\partial l}{\partial A_2}^T d A_2\right) = \text{tr}\left( \frac{\partial l}{\partial A_2}^T dW_2 H_1 \right) + \underbrace{\text{tr}\left(\frac{\partial l}{\partial A_2}^T W_2 d H_1\right)}_{dl_2} + \text{tr}\left(\frac{\partial l}{\partial A_2}^T d \boldsymbol{b}_2 \boldsymbol{1}^T\right)](https://www.zhihu.com/equation?tex=dl+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+A_2%7D%5ET+d+A_2%5Cright%29+%3D+%5Ctext%7Btr%7D%5Cleft%28+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+A_2%7D%5ET+dW_2+H_1+%5Cright%29+%2B+%5Cunderbrace%7B%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+A_2%7D%5ET+W_2+d+H_1%5Cright%29%7D_%7Bdl_2%7D+%2B+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+A_2%7D%5ET+d+%5Cboldsymbol%7Bb%7D_2+%5Cboldsymbol%7B1%7D%5ET%5Cright%29)，从第一项得到![\frac{\partial l}{\partial W_2}= \frac{\partial l}{\partial A_2}H_1^T](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+W_2%7D%3D+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+A_2%7DH_1%5ET)，从第二项得到![\frac{\partial l}{\partial H_1}= W_2^T\frac{\partial l}{\partial A_{2}}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+H_1%7D%3D+W_2%5ET%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+A_%7B2%7D%7D)，从第三项得到到![\frac{\partial l}{\partial \boldsymbol{b}_2}= \frac{\partial l}{\partial A_2}\boldsymbol{1}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Bb%7D_2%7D%3D+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+A_2%7D%5Cboldsymbol%7B1%7D)。接下来对第二项继续使用复合法则，得到![\frac{\partial l}{\partial A_1}= \frac{\partial l}{\partial H_1}\odot\sigma'(A_1)](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+A_1%7D%3D+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+H_1%7D%5Codot%5Csigma%27%28A_1%29)。为求![\frac{\partial l}{\partial W_1}, \frac{\partial l}{\partial \boldsymbol{b}_1}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+W_1%7D%2C+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Bb%7D_1%7D)，再用一次复合法则：![dl_2 = \text{tr}\left(\frac{\partial l}{\partial A_1}^TdA_1\right) = \text{tr}\left(\frac{\partial l}{\partial A_1}^TdW_1X\right) + \text{tr}\left( \frac{\partial l}{\partial A_1}^Td\boldsymbol{b}_1 \boldsymbol{1}^T\right)](https://www.zhihu.com/equation?tex=dl_2+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+A_1%7D%5ETdA_1%5Cright%29+%3D+%5Ctext%7Btr%7D%5Cleft%28%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+A_1%7D%5ETdW_1X%5Cright%29+%2B+%5Ctext%7Btr%7D%5Cleft%28+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+A_1%7D%5ETd%5Cboldsymbol%7Bb%7D_1+%5Cboldsymbol%7B1%7D%5ET%5Cright%29)，得到![\frac{\partial l}{\partial W_1}=  \frac{\partial l}{\partial A_1}X^T](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+W_1%7D%3D++%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+A_1%7DX%5ET)，![\frac{\partial l}{\partial \boldsymbol{b}_1}= \frac{\partial l}{\partial A_1}\boldsymbol{1}](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+%5Cboldsymbol%7Bb%7D_1%7D%3D+%5Cfrac%7B%5Cpartial+l%7D%7B%5Cpartial+A_1%7D%5Cboldsymbol%7B1%7D)。